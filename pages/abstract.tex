\chapter{\abstractname}
Estimate the pose of camera, is a principal part of augmented reality. In this master thesis, we developed a new approach to find out the pose estimation of monocular camera using the features points. At first, all input frames are grouped into small same sized (usually 5 frames) packages called bundles. After that the features of all frames in a bundle are extracted by A-KAZE Features Extraction. The N-best features, which are visible from all frames and their feature descriptors are similar, are selected as robust features by a recursive approach and robust feature matcher. These N features from all (5) frames, reconstruct N new 3D points. These 3D points are refined by a bundle adjustment (local).

After the processing of each bundle the 3D world map is updated by resulting 3D points. For this one, the N new 3D Points, are compared to existing world map and is updated by the points that are available in all frame of all bundles. A bundle adjustment (global) is applied to optimize the 3D points in world map. The pose is estimated using the feature points in each frame and the 3D points in the world map by applying the PnP algorithm. The world map after a certain iterations (usually 35 frames), is cleared and assigned directly by the N new points from local bundle adjustment.

It should be noted that the novelty of this approach is two-fold: First the new robust feature matcher that consists of four layers for filtering the outlier features; Second, grouping the input frames into bundles and applying the local and global bundle adjustment. The outcome is significantly accurate in comparison to the ground truth data which were extracted by Ubitrack marker pose estimation and ARTRACK2 cameras.